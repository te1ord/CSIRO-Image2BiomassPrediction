{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7c7b67",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-01T00:19:34.256738Z",
     "iopub.status.busy": "2025-11-01T00:19:34.256529Z",
     "iopub.status.idle": "2025-11-01T00:19:44.234866Z",
     "shell.execute_reply": "2025-11-01T00:19:44.233820Z"
    },
    "papermill": {
     "duration": 9.982923,
     "end_time": "2025-11-01T00:19:44.236343",
     "exception": false,
     "start_time": "2025-11-01T00:19:34.253420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/kaggle/input/rsna-models/facebookresearch_dinov2_main (1)/root/.cache/torch/hub/facebookresearch_dinov2_main': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from PIL import Image\n",
    "!cp -r \"/kaggle/input/rsna-models/facebookresearch_dinov2_main (1)/root/.cache/torch/hub/facebookresearch_dinov2_main\" /kaggle/working/dinov2\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766d138f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:19:44.242048Z",
     "iopub.status.busy": "2025-11-01T00:19:44.241489Z",
     "iopub.status.idle": "2025-11-01T00:20:09.883371Z",
     "shell.execute_reply": "2025-11-01T00:20:09.882514Z"
    },
    "papermill": {
     "duration": 25.646033,
     "end_time": "2025-11-01T00:20:09.884802",
     "exception": false,
     "start_time": "2025-11-01T00:19:44.238769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 00:19:48.317210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761956388.507721      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761956388.564515      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1/')\n",
    "model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1/')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f5bac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:20:09.890797Z",
     "iopub.status.busy": "2025-11-01T00:20:09.890186Z",
     "iopub.status.idle": "2025-11-01T00:21:02.830680Z",
     "shell.execute_reply": "2025-11-01T00:21:02.830078Z"
    },
    "papermill": {
     "duration": 52.944937,
     "end_time": "2025-11-01T00:21:02.832231",
     "exception": false,
     "start_time": "2025-11-01T00:20:09.887294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3300202635.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  x = torch.tensor(processor(img).pixel_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 batches processed.\n",
      "200 batches processed.\n",
      "300 batches processed.\n"
     ]
    }
   ],
   "source": [
    "embeds = []\n",
    "targets = [[] for i in range(5)]\n",
    "counter = 0\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "#transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std)])\n",
    "train_df = pd.read_csv(\"/kaggle/input/csiro-biomass/train.csv\")\n",
    "root = \"/kaggle/input/csiro-biomass/\"\n",
    "for i in range(len(train_df)):\n",
    "    entry = train_df.iloc[i]\n",
    "    file_path = root + entry['image_path']\n",
    "    y = torch.tensor([[entry['target']]])\n",
    "    targets[i % 5].append(y)\n",
    "    if i % 5 == 0:\n",
    "        img = Image.open(file_path)\n",
    "        x = torch.tensor(processor(img).pixel_values)\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda()\n",
    "            embeds.append(model(x).pooler_output.cpu())\n",
    "            counter += 1\n",
    "            if counter % 100 == 0:\n",
    "                print(f\"{counter} batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2502d9a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:21:02.838385Z",
     "iopub.status.busy": "2025-11-01T00:21:02.838136Z",
     "iopub.status.idle": "2025-11-01T00:21:03.287498Z",
     "shell.execute_reply": "2025-11-01T00:21:03.286626Z"
    },
    "papermill": {
     "duration": 0.453815,
     "end_time": "2025-11-01T00:21:03.288888",
     "exception": false,
     "start_time": "2025-11-01T00:21:02.835073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Target 1 ===\n",
      "Fold 1:\n",
      "  Train R²: 0.6520\n",
      "  Val R²: 0.4083\n",
      "Fold 2:\n",
      "  Train R²: 0.6006\n",
      "  Val R²: 0.6426\n",
      "Fold 3:\n",
      "  Train R²: 0.6318\n",
      "  Val R²: 0.5823\n",
      "Fold 4:\n",
      "  Train R²: 0.6516\n",
      "  Val R²: 0.4472\n",
      "Fold 5:\n",
      "  Train R²: 0.6311\n",
      "  Val R²: 0.4461\n",
      "\n",
      "Target 1 Average:\n",
      "  Avg Train R²: 0.6334\n",
      "  Avg Val R²: 0.5053\n",
      "\n",
      "=== Target 2 ===\n",
      "Fold 1:\n",
      "  Train R²: 0.4422\n",
      "  Val R²: 0.3771\n",
      "Fold 2:\n",
      "  Train R²: 0.4612\n",
      "  Val R²: 0.1990\n",
      "Fold 3:\n",
      "  Train R²: 0.4716\n",
      "  Val R²: 0.3107\n",
      "Fold 4:\n",
      "  Train R²: 0.4591\n",
      "  Val R²: 0.3874\n",
      "Fold 5:\n",
      "  Train R²: 0.4195\n",
      "  Val R²: 0.4719\n",
      "\n",
      "Target 2 Average:\n",
      "  Avg Train R²: 0.4507\n",
      "  Avg Val R²: 0.3492\n",
      "\n",
      "=== Target 3 ===\n",
      "Fold 1:\n",
      "  Train R²: 0.8262\n",
      "  Val R²: 0.7079\n",
      "Fold 2:\n",
      "  Train R²: 0.8337\n",
      "  Val R²: 0.6208\n",
      "Fold 3:\n",
      "  Train R²: 0.8339\n",
      "  Val R²: 0.6039\n",
      "Fold 4:\n",
      "  Train R²: 0.8342\n",
      "  Val R²: 0.6463\n",
      "Fold 5:\n",
      "  Train R²: 0.8227\n",
      "  Val R²: 0.7007\n",
      "\n",
      "Target 3 Average:\n",
      "  Avg Train R²: 0.8301\n",
      "  Avg Val R²: 0.6559\n",
      "\n",
      "=== Target 4 ===\n",
      "Fold 1:\n",
      "  Train R²: 0.7606\n",
      "  Val R²: 0.5641\n",
      "Fold 2:\n",
      "  Train R²: 0.7942\n",
      "  Val R²: 0.4437\n",
      "Fold 3:\n",
      "  Train R²: 0.7686\n",
      "  Val R²: 0.5105\n",
      "Fold 4:\n",
      "  Train R²: 0.7600\n",
      "  Val R²: 0.5493\n",
      "Fold 5:\n",
      "  Train R²: 0.7635\n",
      "  Val R²: 0.5781\n",
      "\n",
      "Target 4 Average:\n",
      "  Avg Train R²: 0.7693\n",
      "  Avg Val R²: 0.5291\n",
      "\n",
      "=== Target 5 ===\n",
      "Fold 1:\n",
      "  Train R²: 0.8107\n",
      "  Val R²: 0.6607\n",
      "Fold 2:\n",
      "  Train R²: 0.8266\n",
      "  Val R²: 0.6512\n",
      "Fold 3:\n",
      "  Train R²: 0.8256\n",
      "  Val R²: 0.5745\n",
      "Fold 4:\n",
      "  Train R²: 0.8244\n",
      "  Val R²: 0.6079\n",
      "Fold 5:\n",
      "  Train R²: 0.8056\n",
      "  Val R²: 0.6609\n",
      "\n",
      "Target 5 Average:\n",
      "  Avg Train R²: 0.8186\n",
      "  Avg Val R²: 0.6310\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Create indices and shuffle once\n",
    "lst = list(range(len(embeds)))\n",
    "random.seed(42)\n",
    "random.shuffle(lst)\n",
    "\n",
    "# Create multiple random 80/20 splits\n",
    "n_splits = 5\n",
    "splits = []\n",
    "\n",
    "for i in range(n_splits):\n",
    "    # Reshuffle for each split while maintaining same splits across targets\n",
    "    temp_lst = lst.copy()\n",
    "    random.seed(42 + i)  # Different seed for each split\n",
    "    random.shuffle(temp_lst)\n",
    "    \n",
    "    split_point = int(len(temp_lst) * 0.8)\n",
    "    train_idxs = temp_lst[:split_point]\n",
    "    val_idxs = temp_lst[split_point:]\n",
    "    splits.append((train_idxs, val_idxs))\n",
    "\n",
    "# Convert embeds to numpy array once for efficiency\n",
    "embeds_np = np.array(torch.cat(embeds))\n",
    "regressors = [[None for i in range(5)] for j in range(5)]\n",
    "# Now iterate through each target\n",
    "for i in range(5):\n",
    "    print(f\"\\n=== Target {i+1} ===\")\n",
    "    targets_np = np.array(torch.cat(targets[i]))\n",
    "    \n",
    "    split_scores = []\n",
    "    \n",
    "    for split_idx, (train_idxs, val_idxs) in enumerate(splits):\n",
    "        print(f\"Fold {split_idx+1}:\")\n",
    "        X_train, y_train = embeds_np[train_idxs], targets_np[train_idxs]\n",
    "        X_val, y_val = embeds_np[val_idxs], targets_np[val_idxs]\n",
    "        reg = Lasso()\n",
    "        reg.fit(X_train, y_train)\n",
    "        train_preds = reg.predict(X_train)\n",
    "        train_preds[train_preds < 0.0] = 0.0\n",
    "        train_r2 = r2_score(y_train, train_preds)\n",
    "        val_preds = reg.predict(X_val)\n",
    "        val_preds[val_preds < 0.0] = 0.0\n",
    "        val_r2 = r2_score(y_val, val_preds)\n",
    "        print(f\"  Train R²: {train_r2:.4f}\")\n",
    "        print(f\"  Val R²: {val_r2:.4f}\")\n",
    "        split_scores.append((train_r2, val_r2))\n",
    "        regressors[i][split_idx] = reg\n",
    "    \n",
    "    # Print summary for this target\n",
    "    avg_train_r2 = np.mean([score[0] for score in split_scores])\n",
    "    avg_val_r2 = np.mean([score[1] for score in split_scores])\n",
    "    print(f\"\\nTarget {i+1} Average:\")\n",
    "    print(f\"  Avg Train R²: {avg_train_r2:.4f}\")\n",
    "    print(f\"  Avg Val R²: {avg_val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baed7a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:21:03.295447Z",
     "iopub.status.busy": "2025-11-01T00:21:03.294766Z",
     "iopub.status.idle": "2025-11-01T00:21:03.298372Z",
     "shell.execute_reply": "2025-11-01T00:21:03.297766Z"
    },
    "papermill": {
     "duration": 0.007811,
     "end_time": "2025-11-01T00:21:03.299416",
     "exception": false,
     "start_time": "2025-11-01T00:21:03.291605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping = {\"Dry_Clover_g\": 0, \"Dry_Dead_g\": 1, \"Dry_Green_g\": 2, \"Dry_Total_g\": 3, \"GDM_g\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4238f324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:21:03.305278Z",
     "iopub.status.busy": "2025-11-01T00:21:03.305054Z",
     "iopub.status.idle": "2025-11-01T00:21:03.906552Z",
     "shell.execute_reply": "2025-11-01T00:21:03.905961Z"
    },
    "papermill": {
     "duration": 0.605696,
     "end_time": "2025-11-01T00:21:03.907787",
     "exception": false,
     "start_time": "2025-11-01T00:21:03.302091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_embeds = {}\n",
    "counter = 0\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std)])\n",
    "test_df = pd.read_csv(\"/kaggle/input/csiro-biomass/test.csv\")\n",
    "root = \"/kaggle/input/csiro-biomass/\"\n",
    "sample_ids = []\n",
    "for i in range(len(test_df)):\n",
    "    entry = test_df.iloc[i]\n",
    "    file_path = root + entry['image_path']\n",
    "    sample_id = entry['sample_id']\n",
    "    #y = torch.tensor([[entry['target']]])\n",
    "    if sample_id not in sample_ids:\n",
    "        img = Image.open(file_path)\n",
    "        x = torch.tensor(processor(img).pixel_values)\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda()\n",
    "            test_embeds[sample_id.split(\"_\")[0]] = model(x).pooler_output.cpu()\n",
    "            counter += 1\n",
    "        sample_ids.append(sample_id)\n",
    "    if counter % 100 == 0:\n",
    "        print(f\"{counter} batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab64d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:21:03.913636Z",
     "iopub.status.busy": "2025-11-01T00:21:03.913409Z",
     "iopub.status.idle": "2025-11-01T00:21:03.924507Z",
     "shell.execute_reply": "2025-11-01T00:21:03.923625Z"
    },
    "papermill": {
     "duration": 0.015147,
     "end_time": "2025-11-01T00:21:03.925597",
     "exception": false,
     "start_time": "2025-11-01T00:21:03.910450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "sample_ids = []\n",
    "test_df = pd.read_csv(\"/kaggle/input/csiro-biomass/test.csv\")\n",
    "for i in range(len(test_df)):\n",
    "    try:\n",
    "        entry = test_df.iloc[i]\n",
    "        X = np.array(test_embeds[entry['sample_id'].split(\"__\")[0]])\n",
    "        sample_ids.append(entry['sample_id'])\n",
    "        models = regressors[mapping[entry['sample_id'].split(\"__\")[1]]]\n",
    "        prediction = 0.0\n",
    "        for item in models:\n",
    "            single_pred = item.predict(X)\n",
    "            if single_pred < 0.0:\n",
    "                single_pred = 0.0\n",
    "            prediction += single_pred\n",
    "        prediction = prediction / 5\n",
    "        predictions.append(float(prediction))\n",
    "    except Exception as e:\n",
    "        predictions.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8139994b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:21:03.931218Z",
     "iopub.status.busy": "2025-11-01T00:21:03.930996Z",
     "iopub.status.idle": "2025-11-01T00:21:03.951949Z",
     "shell.execute_reply": "2025-11-01T00:21:03.951290Z"
    },
    "papermill": {
     "duration": 0.024964,
     "end_time": "2025-11-01T00:21:03.953041",
     "exception": false,
     "start_time": "2025-11-01T00:21:03.928077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1001187975__Dry_Clover_g</td>\n",
       "      <td>1.975965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1001187975__Dry_Dead_g</td>\n",
       "      <td>22.272205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1001187975__Dry_Green_g</td>\n",
       "      <td>31.084332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1001187975__Dry_Total_g</td>\n",
       "      <td>55.230492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1001187975__GDM_g</td>\n",
       "      <td>28.500387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id     target\n",
       "0  ID1001187975__Dry_Clover_g   1.975965\n",
       "1    ID1001187975__Dry_Dead_g  22.272205\n",
       "2   ID1001187975__Dry_Green_g  31.084332\n",
       "3   ID1001187975__Dry_Total_g  55.230492\n",
       "4         ID1001187975__GDM_g  28.500387"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': sample_ids,\n",
    "    'target': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa38aad",
   "metadata": {
    "papermill": {
     "duration": 0.002326,
     "end_time": "2025-11-01T00:21:03.957932",
     "exception": false,
     "start_time": "2025-11-01T00:21:03.955606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 986,
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 95.892185,
   "end_time": "2025-11-01T00:21:06.691429",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-01T00:19:30.799244",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
